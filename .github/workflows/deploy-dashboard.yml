name: ğŸŒ Deploy Dashboard to GitHub Pages

on:
  schedule:
    # Update dashboard every 30 minutes (same as monitoring)
    - cron: '*/30 * * * *'
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force dashboard regeneration'
        required: false
        default: 'false'
  # Trigger immediately after successful monitoring runs
  workflow_run:
    workflows: ["URL Monitor"]
    types:
      - completed
    branches: [main]
  # Also trigger on any push (for immediate updates during development)
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'public/**'
      - '.github/workflows/url-monitor.yml'

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  generate-dashboard:
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: ğŸ”§ Install dependencies
        run: npm ci

      - name: ğŸ—ï¸ Build TypeScript
        run: npm run build

      - name: ğŸ“Š Download latest database (workflow_run trigger)
        if: github.event_name == 'workflow_run'
        uses: actions/download-artifact@v4
        with:
          name: monitoring-database
          path: ./
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
        continue-on-error: true

      - name: ğŸ“Š Download latest database (manual/push trigger)
        if: github.event_name != 'workflow_run'
        uses: actions/download-artifact@v4
        with:
          name: monitoring-database
          path: ./
        continue-on-error: true

      - name: ğŸ¨ Generate static dashboard
        run: |
          # Create static dashboard directory
          mkdir -p static-dashboard
          cp -r public/* static-dashboard/
          
          # Create API directory for static files
          mkdir -p static-dashboard/api
          
          # Generate empty API responses (will be populated by monitoring data later)
          echo '[]' > static-dashboard/api/groups.json
          echo '[]' > static-dashboard/api/results.json
          echo '[]' > static-dashboard/api/status-codes.json
          echo '[]' > static-dashboard/api/failed-requests.json
          
          # If database exists, try to generate real data
          if [ -f "monitoring.db" ]; then
            echo "ğŸ“Š Database found, generating static API data..."
            
            # Install sqlite3 for data extraction
            sudo apt-get update && sudo apt-get install -y sqlite3
            
            # Check if tables exist and have data
            TABLE_COUNT=$(sqlite3 monitoring.db ".tables" | wc -l)
            if [ "$TABLE_COUNT" -gt 0 ]; then
              RECORD_COUNT=$(sqlite3 monitoring.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
              echo "ğŸ“‹ Found $RECORD_COUNT records in database"
              
              if [ "$RECORD_COUNT" -gt 0 ]; then
                echo "ğŸ”„ Extracting real data from database..."
                
                # Generate groups data with real statistics
                sqlite3 -json monitoring.db "
                  SELECT 
                    CASE 
                      WHEN name LIKE '%Max%' OR url LIKE '%max.com%' THEN 'Max Streaming'
                      WHEN name LIKE '%D+%' OR name LIKE '%Discovery%' OR url LIKE '%discoveryplus%' THEN 'Discovery Plus'
                      ELSE 'Other'
                    END as group_name,
                    COUNT(*) as total_requests,
                    ROUND(AVG(CASE WHEN success = 1 THEN 100.0 ELSE 0.0 END), 1) as success_rate,
                    ROUND(AVG(responseTime), 0) as avg_response_time,
                    COUNT(DISTINCT url) as url_count
                  FROM requests 
                  WHERE timestamp >= datetime('now', '-24 hours')
                  GROUP BY 
                    CASE 
                      WHEN name LIKE '%Max%' OR url LIKE '%max.com%' THEN 'Max Streaming'
                      WHEN name LIKE '%D+%' OR name LIKE '%Discovery%' OR url LIKE '%discoveryplus%' THEN 'Discovery Plus'
                      ELSE 'Other'
                    END
                " > static-dashboard/api/groups.json
                
                # Generate recent results data
                sqlite3 -json monitoring.db "
                  SELECT 
                    id,
                    url,
                    name,
                    datetime(timestamp) as timestamp,
                    status,
                    responseTime,
                    success,
                    error
                  FROM requests 
                  WHERE timestamp >= datetime('now', '-24 hours')
                  ORDER BY timestamp DESC 
                  LIMIT 1000
                " > static-dashboard/api/results.json
                
                # Generate status codes data
                sqlite3 -json monitoring.db "
                  SELECT 
                    status,
                    COUNT(*) as count,
                    name,
                    url
                  FROM requests 
                  WHERE timestamp >= datetime('now', '-24 hours')
                  GROUP BY status, name, url
                  ORDER BY status, count DESC
                " > static-dashboard/api/status-codes.json
                
                # Generate failed requests data
                sqlite3 -json monitoring.db "
                  SELECT 
                    id,
                    url,
                    name,
                    datetime(timestamp) as timestamp,
                    status,
                    responseTime,
                    error
                  FROM requests 
                  WHERE success = 0 AND timestamp >= datetime('now', '-24 hours')
                  ORDER BY timestamp DESC
                " > static-dashboard/api/failed-requests.json
                
                echo "âœ… Generated real API data from $RECORD_COUNT database records"
              else
                echo "ğŸ“ Database exists but no records found, using empty data"
              fi
            else
              echo "ğŸ“ Database exists but no tables found yet"
            fi
          else
            echo "ğŸ“ No database found, using empty API responses"
          fi
          
          # Add timestamp to dashboard
          echo "<!-- Last updated: $(date -u) -->" >> static-dashboard/index.html
          echo "<!-- Database status: $([ -f "monitoring.db" ] && echo "Found" || echo "Not found") -->" >> static-dashboard/index.html

      - name: ğŸ” Debug - List generated files
        run: |
          echo "=== Generated Dashboard Files ==="
          ls -la static-dashboard/
          echo ""
          echo "=== API Files ==="
          ls -la static-dashboard/api/
          echo ""
          echo "=== Groups JSON Content ==="
          cat static-dashboard/api/groups.json

      - name: ğŸ“¤ Setup Pages
        uses: actions/configure-pages@v4

      - name: ğŸš€ Upload to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: './static-dashboard'

      - name: ğŸŒ Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: ğŸ“ Summary
        run: |
          echo "ğŸŒ **Dashboard deployed successfully!**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“Š **Dashboard URL:** https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ”„ **Last updated:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“ **Files deployed:** $(ls -la static-dashboard/ | wc -l) files" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ’¾ **Database found:** $([ -f "monitoring.db" ] && echo "Yes" || echo "No")" >> $GITHUB_STEP_SUMMARY
