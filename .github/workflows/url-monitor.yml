name: URL Monitor

on:
  schedule:
    - cron: '*/15 * * * *'  # Every 15 minutes following your project requirements
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Force monitoring run'
        required: false
        default: 'false'
      time_range_hours:
        description: 'Hours of data for dashboard (default: 24)'
        required: false
        default: '24'

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "url-monitor"
  cancel-in-progress: false

jobs:
  monitor-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout repository with full history
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: ğŸ”§ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: ğŸ“¦ Install dependencies
      run: npm ci

    - name: ğŸ—ï¸ Build TypeScript following your project structure
      run: npm run build

    - name: ğŸ“Š Restore existing database from repository
      run: |
        echo "ğŸ” Checking for existing database in repository..."
        if [ -f "data/monitor.db" ]; then
          echo "âœ… Found existing database in repository: data/monitor.db"
          cp data/monitor.db monitor.db
          
          # Verify database integrity following your database.ts schema
          RECORD_COUNT=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
          echo "ğŸ“Š Current records: $RECORD_COUNT"
          
          if [ "$RECORD_COUNT" -gt 0 ]; then
            echo "ğŸ” Database health check:"
            sqlite3 monitor.db "
              SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT url) as unique_urls,
                MIN(datetime(timestamp)) as oldest_record,
                MAX(datetime(timestamp)) as newest_record
              FROM requests;
            " 2>/dev/null || echo "Database health check failed"
            
            echo "ğŸ“ˆ Recent activity:"
            sqlite3 monitor.db "
              SELECT 
                COUNT(*) as recent_checks,
                ROUND(AVG(CASE WHEN success = 1 THEN 100.0 ELSE 0.0 END), 1) || '%' as success_rate
              FROM requests 
              WHERE datetime(timestamp) >= datetime('now', '-24 hours');
            " 2>/dev/null || echo "No recent activity"
          fi
        else
          echo "ğŸ†• No existing database found in repository"
          echo "ğŸ“ Creating data directory for database storage"
          mkdir -p data
        fi

    - name: ğŸ—„ï¸ Initialize database following your SQLite schema
      run: |
        if [ ! -f "monitor.db" ]; then
          echo "ğŸ”§ Creating fresh database with your project schema..."
          sqlite3 monitor.db "
            CREATE TABLE IF NOT EXISTS requests (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              url TEXT NOT NULL,
              name TEXT NOT NULL,
              countryCode TEXT,
              group_name TEXT,
              timestamp TEXT NOT NULL,
              status INTEGER NOT NULL,
              responseTime INTEGER NOT NULL,
              success BOOLEAN NOT NULL,
              error TEXT
            );
            CREATE INDEX IF NOT EXISTS idx_requests_timestamp ON requests(timestamp);
            CREATE INDEX IF NOT EXISTS idx_requests_url ON requests(url);
            CREATE INDEX IF NOT EXISTS idx_requests_group_name ON requests(group_name);
            CREATE INDEX IF NOT EXISTS idx_requests_country ON requests(countryCode);
          "
          echo "âœ… Fresh database initialized with your monitoring schema"
        else
          echo "âœ… Using existing database with historical data"
        fi

    - name: ğŸ“‹ Verify CSV configuration following your guidelines
      run: |
        if [ ! -f "urls.csv" ]; then
          echo "âš ï¸ urls.csv not found, creating sample following your format"
          cat > urls.csv << 'EOF'
        url,name,countryCode,group_name
        https://httpstat.us/200,HTTP Status 200,US,API Tests
        https://httpstat.us/404,HTTP Status 404,US,API Tests
        https://httpstat.us/500,HTTP Status 500,US,API Tests
        https://httpbin.org/delay/1,HTTPBin Delay Test,GB,Network Tests
        https://httpbin.org/status/500,Server Error Test,DE,Error Tests
        https://www.google.com,Google Homepage,US,Production Sites
        https://github.com,GitHub,US,Development Tools
        https://www.example.com/nonexistent,Broken Link Test,CA,Error Tests
        EOF
          echo "âœ… Created sample urls.csv with group_name column following your CSV format"
        else
          echo "âœ… urls.csv found"
          echo "ğŸ“‹ CSV structure verification:"
          head -1 urls.csv
          echo "ğŸ“‹ URLs configured for monitoring:"
          head -10 urls.csv
          
          # Verify group_name column exists
          if head -1 urls.csv | grep -q "group_name"; then
            echo "âœ… group_name column found in CSV"
            UNIQUE_GROUPS=$(tail -n +2 urls.csv | cut -d',' -f4 | sort | uniq | wc -l)
            echo "ğŸ“Š Unique groups in CSV: $UNIQUE_GROUPS"
          else
            echo "âš ï¸ group_name column missing from CSV - groups will be empty"
          fi
        fi

    - name: ğŸ”„ Run headless URL monitoring following your main-headless.ts pattern
      env:
        URLS_CSV_PATH: urls.csv
        MONITOR_TIMEOUT: 30000
        DATABASE_PATH: monitor.db
        CHECK_INTERVAL: 60000
      run: |
        echo "ğŸ”„ Starting URL monitoring cycle using your headless application..."
        
        # Record pre-monitoring stats
        PRE_COUNT=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
        echo "ğŸ“Š Records before monitoring: $PRE_COUNT"
        
        # Run monitoring
        npm run headless
        
        # Record post-monitoring stats
        POST_COUNT=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
        NEW_RECORDS=$((POST_COUNT - PRE_COUNT))
        echo "ğŸ“ˆ Records after monitoring: $POST_COUNT"
        echo "ğŸ†• New records added: $NEW_RECORDS"

    - name: ğŸ“ˆ Verify monitoring results following your database schema
      run: |
        if [ -f "monitor.db" ]; then
          echo "âœ… Monitoring cycle completed successfully"
          
          # Database statistics following your schema
          TOTAL_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
          RECENT_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests WHERE datetime(timestamp) >= datetime('now', '-1 hour');" 2>/dev/null || echo "0")
          
          echo "ğŸ“Š Database Statistics:"
          echo "   ğŸ“‹ Total records: $TOTAL_RECORDS"
          echo "   ğŸ”„ Records this hour: $RECENT_RECORDS"
          echo "   ğŸ’¾ Database size: $(ls -lh monitor.db | awk '{print $5}')"
          
          # Show recent results following your API endpoint structure
          echo "ğŸ” Recent monitoring results:"
          sqlite3 monitor.db "
            SELECT 
              name, 
              status, 
              responseTime || 'ms' as response_time,
              CASE WHEN success = 1 THEN 'âœ…' ELSE 'âŒ' END as result,
              COALESCE(group_name, 'Ungrouped') as group_name,
              datetime(timestamp, 'localtime') as checked_at
            FROM requests 
            ORDER BY timestamp DESC 
            LIMIT 8;
          " 2>/dev/null | column -t || echo "No results to display yet"
          
          # Success rate statistics by group
          echo ""
          echo "ğŸ“ˆ Success rates by group (last 24 hours):"
          sqlite3 monitor.db "
            SELECT 
              COALESCE(group_name, 'Ungrouped') as group_name,
              COUNT(*) as total_checks,
              ROUND(AVG(CASE WHEN success = 1 THEN 100.0 ELSE 0.0 END), 1) || '%' as success_rate,
              ROUND(AVG(responseTime), 0) || 'ms' as avg_response_time
            FROM requests 
            WHERE datetime(timestamp) >= datetime('now', '-24 hours')
            GROUP BY group_name
            ORDER BY group_name;
          " 2>/dev/null | column -t || echo "No group statistics available yet"
          
        else
          echo "âŒ Database file not found after monitoring cycle"
          exit 1
        fi

    - name: ğŸ’¾ Save database to repository BEFORE generating API files
      run: |
        echo "ğŸ’¾ Saving database to repository for persistence..."
        
        # Ensure data directory exists
        mkdir -p data
        
        # Copy current database to repository storage
        cp monitor.db data/monitor.db
        
        # Create timestamped backup following your backup strategy
        BACKUP_NAME="monitor-backup-$(date -u +%Y%m%d-%H%M%S).db"
        cp monitor.db "data/$BACKUP_NAME"
        
        echo "âœ… Database saved:"
        echo "   ğŸ“ Primary: data/monitor.db ($(ls -lh data/monitor.db | awk '{print $5}'))"
        echo "   ğŸ—„ï¸ Backup: data/$BACKUP_NAME"
        
        # Keep only last 10 backups to prevent repository bloat
        cd data
        ls -t monitor-backup-*.db 2>/dev/null | tail -n +11 | xargs -r rm
        BACKUP_COUNT=$(ls monitor-backup-*.db 2>/dev/null | wc -l)
        echo "ğŸ§¹ Backup cleanup completed, keeping $BACKUP_COUNT backups"

    - name: ğŸ“„ Generate static API files following your endpoint structure
      run: |
        echo "ğŸ“„ Generating static API files for GitHub Pages deployment..."
        mkdir -p public/api
        
        TIME_RANGE="${{ github.event.inputs.time_range_hours || '24' }}"
        echo "â±ï¸ Using time range: $TIME_RANGE hours"
        
        # Verify database exists and has data
        if [ ! -f "monitor.db" ]; then
          echo "âŒ Database file not found!"
          exit 1
        fi
        
        TOTAL_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
        FAILED_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests WHERE success = 0;" 2>/dev/null || echo "0")
        RECENT_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests WHERE datetime(timestamp) >= datetime('now', '-$TIME_RANGE hours');" 2>/dev/null || echo "0")
        
        echo "ğŸ“Š Database verification:"
        echo "   Total records: $TOTAL_RECORDS"
        echo "   Failed records: $FAILED_RECORDS"
        echo "   Recent records ($TIME_RANGE hours): $RECENT_RECORDS"
        
        # Debug: Show sample data structure
        echo "ğŸ” Sample database records:"
        sqlite3 monitor.db "
          SELECT 
            'Sample record:' as debug,
            url, name, group_name, countryCode, success, status, error
          FROM requests 
          ORDER BY timestamp DESC 
          LIMIT 3;
        " 2>/dev/null || echo "No sample records available"
        
        # Generate results.json following your GET /api/results endpoint
        echo "ğŸ“Š Generating results.json..."
        sqlite3 monitor.db -json "
          SELECT 
            id, url, name, countryCode, group_name, timestamp, 
            status, responseTime, success, error
          FROM requests 
          WHERE datetime(timestamp) >= datetime('now', '-$TIME_RANGE hours') 
          ORDER BY timestamp DESC
          LIMIT 10000;
        " > public/api/results.json 2>/dev/null || echo "[]" > public/api/results.json
        
        RESULTS_COUNT=$(jq length public/api/results.json 2>/dev/null || echo "0")
        echo "   âœ… Results: $RESULTS_COUNT entries"
        
        # Generate stats.json following your GET /api/stats endpoint  
        echo "ğŸ“ˆ Generating stats.json..."
        sqlite3 monitor.db -json "
          SELECT 
            url, name, group_name, countryCode,
            COUNT(*) as totalRequests,
            SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successfulRequests,
            SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as failedRequests,
            ROUND(AVG(CASE WHEN success = 1 THEN 1.0 ELSE 0.0 END) * 100, 2) as successRate,
            ROUND(AVG(responseTime), 0) as averageResponseTime,
            MAX(timestamp) as lastChecked,
            (SELECT status FROM requests r2 WHERE r2.url = requests.url ORDER BY timestamp DESC LIMIT 1) as lastStatus
          FROM requests 
          WHERE datetime(timestamp) >= datetime('now', '-$TIME_RANGE hours')
          GROUP BY url, name, group_name, countryCode
          ORDER BY name;
        " > public/api/stats.json 2>/dev/null || echo "[]" > public/api/stats.json
        
        STATS_COUNT=$(jq length public/api/stats.json 2>/dev/null || echo "0")
        echo "   âœ… Stats: $STATS_COUNT URLs"
        
        # Generate failed-requests.json following your error handling patterns
        echo "ğŸš¨ Generating failed-requests.json..."
        sqlite3 monitor.db -json "
          SELECT 
            id, url, name, group_name, countryCode, timestamp, 
            status, responseTime, error,
            CASE 
              WHEN error IS NOT NULL THEN error
              WHEN status >= 400 THEN 'HTTP ' || status || ' Error'
              ELSE 'Unknown Error'
            END as errorDescription
          FROM requests 
          WHERE success = 0 AND datetime(timestamp) >= datetime('now', '-$TIME_RANGE hours')
          ORDER BY timestamp DESC
          LIMIT 1000;
        " > public/api/failed-requests.json 2>/dev/null || echo "[]" > public/api/failed-requests.json
        
        FAILED_COUNT=$(jq length public/api/failed-requests.json 2>/dev/null || echo "0")
        echo "   âœ… Failed requests: $FAILED_COUNT failures"
        
        # Show sample failed request if any exist
        if [ "$FAILED_COUNT" -gt 0 ]; then
          echo "ğŸ” Sample failed request:"
          jq '.[0] | {url, name, status, error}' public/api/failed-requests.json 2>/dev/null || echo "Failed to parse sample"
        fi
        
        # Generate group-hierarchy.json following your TypeScript patterns
        echo "ğŸ—ï¸ Generating group-hierarchy.json..."
        
        # First check if we have any group data
        GROUP_DATA_COUNT=$(sqlite3 monitor.db "SELECT COUNT(DISTINCT group_name) FROM requests WHERE group_name IS NOT NULL AND group_name != '';" 2>/dev/null || echo "0")
        echo "   ğŸ“Š Unique groups in database: $GROUP_DATA_COUNT"
        
        if [ "$GROUP_DATA_COUNT" -gt 0 ]; then
          # Show sample group data
          echo "ğŸ” Sample group data:"
          sqlite3 monitor.db "
            SELECT DISTINCT group_name, countryCode, COUNT(*) as url_count
            FROM requests 
            WHERE group_name IS NOT NULL AND group_name != ''
            GROUP BY group_name, countryCode
            ORDER BY group_name
            LIMIT 5;
          " 2>/dev/null || echo "No group data available"
        fi
        
        # Generate group hierarchy with enhanced error handling
        node -e "
          const sqlite3 = require('sqlite3');
          const fs = require('fs');
          
          console.log('ğŸ”§ Starting group hierarchy generation...');
          
          try {
            const db = new sqlite3.Database('monitor.db');
            
            db.all('SELECT DISTINCT group_name, countryCode, url, name FROM requests WHERE group_name IS NOT NULL AND group_name != \"\" ORDER BY group_name, countryCode, name', (err, rows) => {
              if (err) {
                console.error('âŒ Database query error:', err);
                fs.writeFileSync('public/api/group-hierarchy.json', '[]');
                db.close();
                return;
              }
              
              if (!rows || rows.length === 0) {
                console.log('âš ï¸ No group data found in database');
                fs.writeFileSync('public/api/group-hierarchy.json', '[]');
                db.close();
                return;
              }
              
              console.log(\`ğŸ“Š Processing \${rows.length} group records...\`);
              
              const hierarchyMap = new Map();
              rows.forEach((row, index) => {
                if (index < 3) {
                  console.log(\`Sample row \${index + 1}:\`, JSON.stringify(row));
                }
                
                const key = \`\${row.group_name}|\${row.countryCode || 'no-country'}\`;
                if (!hierarchyMap.has(key)) {
                  hierarchyMap.set(key, {
                    group_name: row.group_name,
                    countryCode: row.countryCode || undefined,
                    urls: []
                  });
                }
                
                const entry = hierarchyMap.get(key);
                if (!entry.urls.find(u => u.url === row.url)) {
                  entry.urls.push({ 
                    url: row.url, 
                    name: row.name || row.url 
                  });
                }
              });
              
              const hierarchy = Array.from(hierarchyMap.values());
              
              console.log(\`âœ… Generated hierarchy with \${hierarchy.length} groups\`);
              hierarchy.forEach((group, index) => {
                if (index < 3) {
                  console.log(\`Group \${index + 1}:\`, JSON.stringify(group, null, 2));
                }
              });
              
              fs.writeFileSync('public/api/group-hierarchy.json', JSON.stringify(hierarchy, null, 2));
              console.log('ğŸ’¾ Group hierarchy saved to file');
              
              db.close();
            });
          } catch (error) {
            console.error('âŒ Group hierarchy generation failed:', error);
            require('fs').writeFileSync('public/api/group-hierarchy.json', '[]');
          }
        " 2>&1 || echo "[]" > public/api/group-hierarchy.json
        
        GROUPS_COUNT=$(jq length public/api/group-hierarchy.json 2>/dev/null || echo "0")
        echo "   âœ… Groups: $GROUPS_COUNT hierarchies"
        
        # Generate metadata.json following your API documentation
        echo "â„¹ï¸ Generating metadata.json..."
        cat > public/api/metadata.json << EOF
        {
          "generated": "$(date -u)",
          "totalRecords": $TOTAL_RECORDS,
          "recentRecords": $RECENT_RECORDS,
          "failedRecords": $FAILED_COUNT,
          "timeRange": "$TIME_RANGE hours",
          "workflowRun": "${{ github.run_number }}",
          "repository": "${{ github.repository }}",
          "version": "1.0.0",
          "endpoints": {
            "results": "/api/results.json",
            "stats": "/api/stats.json", 
            "failedRequests": "/api/failed-requests.json",
            "groupHierarchy": "/api/group-hierarchy.json",
            "metadata": "/api/metadata.json"
          }
        }
        EOF
        
        echo "âœ… Generated static API files for GitHub Pages"
        echo ""
        echo "ğŸ“ Final API directory contents:"
        ls -la public/api/
        echo ""
        echo "ğŸ“Š File verification:"
        for file in results.json stats.json failed-requests.json group-hierarchy.json metadata.json; do
          if [ -f "public/api/$file" ]; then
            SIZE=$(ls -lh "public/api/$file" | awk '{print $5}')
            COUNT=$(jq length "public/api/$file" 2>/dev/null || echo "N/A")
            echo "   âœ… $file: $SIZE ($COUNT items)"
          else
            echo "   âŒ $file: MISSING"
          fi
        done
        
        # Verify JSON validity
        echo ""
        echo "ğŸ” JSON validation:"
        for file in public/api/*.json; do
          if jq empty "$file" 2>/dev/null; then
            echo "   âœ… $(basename "$file"): Valid JSON"
          else
            echo "   âŒ $(basename "$file"): Invalid JSON"
            echo "   Content preview: $(head -c 100 "$file")"
          fi
        done    

    
    - name: ğŸ“ Commit database changes to repository
      run: |
        echo "ğŸ“ Preparing to commit database changes..."
        
        # Configure Git for GitHub Actions
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Add all database files
        git add data/
        
        # Check if there are actual changes to commit
        if git diff --staged --quiet; then
          echo "ğŸ“ No database changes to commit (database already up to date)"
        else
          # Get current record count for commit message
          RECORD_COUNT=$(sqlite3 data/monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
          RECENT_COUNT=$(sqlite3 data/monitor.db "SELECT COUNT(*) FROM requests WHERE datetime(timestamp) >= datetime('now', '-1 hour');" 2>/dev/null || echo "0")
          
          # Create descriptive commit message
          COMMIT_MSG="ğŸ“Š Update monitoring database
          
          - Total records: $RECORD_COUNT
          - New records this hour: $RECENT_COUNT
          - Timestamp: $(date -u '+%Y-%m-%d %H:%M UTC')
          - Workflow run: ${{ github.run_number }}"
          
          echo "ğŸ“ Committing database changes..."
          git commit -m "$COMMIT_MSG"
          
          # Push with retry logic for potential conflicts
          echo "ğŸ“¤ Pushing database changes to repository..."
          for i in {1..5}; do
            if git push origin main; then
              echo "âœ… Database changes pushed successfully to repository"
              break
            else
              echo "âš ï¸ Push failed, attempt $i/5. Pulling latest changes..."
              git pull --rebase origin main
              sleep $((i * 2))  # Exponential backoff
            fi
            
            if [ $i -eq 5 ]; then
              echo "âŒ Failed to push after 5 attempts"
              exit 1
            fi
          done
        fi

    - name: ğŸŒ Deploy dashboard to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./public
        enable_jekyll: false
        user_name: 'github-actions[bot]'
        user_email: 'github-actions[bot]@users.noreply.github.com'
        commit_message: 'Update monitoring dashboard - Run ${{ github.run_number }}'

    - name: ğŸ‰ Monitoring cycle summary
      run: |
        echo "ğŸ‰ URL monitoring and dashboard deployment completed!"
        echo ""
        echo "ğŸ“Š Final Summary:"
        TOTAL_RECORDS=$(sqlite3 data/monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
        RECENT_RECORDS=$(sqlite3 data/monitor.db "SELECT COUNT(*) FROM requests WHERE datetime(timestamp) >= datetime('now', '-1 hour');" 2>/dev/null || echo "0")
        
        echo "   ğŸ“‹ Total database records: $TOTAL_RECORDS"
        echo "   ğŸ”„ Records added this hour: $RECENT_RECORDS"
        echo "   ğŸ’¾ Database size: $(ls -lh data/monitor.db | awk '{print $5}' 2>/dev/null || echo 'Unknown')"
        echo "   ğŸ“ API files deployed: $(ls public/api/ 2>/dev/null | wc -l) files"
        echo "   ğŸ—„ï¸ Database backups: $(ls data/monitor-backup-*.db 2>/dev/null | wc -l) files"
        echo ""
        echo "ğŸŒ Dashboard URL: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}"
        echo "â° Next monitoring cycle: $(date -d '+15 minutes' -u '+%Y-%m-%d %H:%M UTC')"
        echo ""
        echo "ğŸ”— API Endpoints:"
        echo "   ğŸ“Š Results: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/api/results.json"
        echo "   ğŸ“ˆ Stats: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/api/stats.json"
        echo "   ğŸ—ï¸ Groups: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/api/group-hierarchy.json"
        echo "   â„¹ï¸ Metadata: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/api/metadata.json"