name: URL Monitor

on:
  schedule:
    - cron: '*/15 * * * *'  # Every 15 minutes
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Force monitoring run'
        required: false
        default: 'false'

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build TypeScript
      run: npm run build

    - name: Check for existing database artifact
      run: |
        echo "🔍 Checking for existing database artifact..."
        # This step always succeeds - we handle missing artifacts gracefully

    - name: Download existing database (graceful failure)
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: monitor-database-artifact
        path: ./

    - name: Initialize database if needed
      run: |
        if [ ! -f "monitor.db" ]; then
          echo "🆕 Creating fresh database file..."
          # Create database with proper schema following your database.ts structure
          sqlite3 monitor.db "
            CREATE TABLE IF NOT EXISTS requests (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              url TEXT NOT NULL,
              name TEXT NOT NULL,
              countryCode TEXT,
              group_name TEXT,
              timestamp TEXT NOT NULL,
              status INTEGER NOT NULL,
              responseTime INTEGER NOT NULL,
              success BOOLEAN NOT NULL,
              error TEXT
            );
            CREATE INDEX IF NOT EXISTS idx_requests_timestamp ON requests(timestamp);
            CREATE INDEX IF NOT EXISTS idx_requests_url ON requests(url);
            CREATE INDEX IF NOT EXISTS idx_requests_group_name ON requests(group_name);
          "
          echo "✅ Fresh database initialized"
        else
          echo "📊 Using existing database"
          RECORD_COUNT=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
          echo "Existing records: $RECORD_COUNT"
        fi

    - name: Verify urls.csv exists
      run: |
        if [ ! -f "urls.csv" ]; then
          echo "⚠️ urls.csv not found, creating sample file"
          cat > urls.csv << 'EOF'
        url,name,countryCode,group_name
        https://httpstat.us/200,HTTP Status 200,US,Test Group
        https://httpstat.us/404,HTTP Status 404,US,Test Group
        https://httpbin.org/delay/1,HTTPBin Delay,GB,Network Tests
        EOF
        else
          echo "✅ urls.csv found"
          echo "URLs to monitor:"
          cat urls.csv | head -10
        fi

    - name: Run headless URL monitoring
      env:
        URLS_CSV_PATH: urls.csv
        MONITOR_TIMEOUT: 30000
        DATABASE_PATH: monitor.db
      run: |
        echo "🔄 Starting URL monitoring cycle..."
        npm run headless

    - name: Verify monitoring results
      run: |
        if [ -f "monitor.db" ]; then
          echo "📈 Monitoring completed successfully"
          
          # Database statistics
          TOTAL_RECORDS=$(sqlite3 monitor.db "SELECT COUNT(*) FROM requests;" 2>/dev/null || echo "0")
          echo "Total database records: $TOTAL_RECORDS"
          
          # Recent results (following your database schema)
          echo "Recent monitoring results:"
          sqlite3 monitor.db "
            SELECT 
              name, 
              status, 
              responseTime || 'ms' as response_time,
              CASE WHEN success = 1 THEN '✅' ELSE '❌' END as result,
              datetime(timestamp, 'localtime') as checked_at
            FROM requests 
            ORDER BY timestamp DESC 
            LIMIT 5;
          " 2>/dev/null || echo "No results to display"
          
        else
          echo "❌ Database file not found after monitoring"
          exit 1
        fi

    - name: Always upload database artifact
      uses: actions/upload-artifact@v4
      with:
        name: monitor-database-artifact
        path: monitor.db
        retention-days: 30
        compression-level: 6
        if-no-files-found: error

    - name: Generate static API files for GitHub Pages
      run: |
        echo "📄 Generating static API files following your API endpoints..."
        mkdir -p public/api
        
        # Generate results.json (matching GET /api/results endpoint)
        sqlite3 monitor.db -json "
          SELECT * FROM requests 
          WHERE datetime(timestamp) >= datetime('now', '-7 days') 
          ORDER BY timestamp DESC;
        " > public/api/results.json 2>/dev/null || echo "[]" > public/api/results.json
        
        # Generate stats.json (matching GET /api/stats endpoint)
        sqlite3 monitor.db -json "
          SELECT 
            url, name, group_name, countryCode,
            COUNT(*) as totalRequests,
            SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successfulRequests,
            SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as failedRequests,
            ROUND(AVG(CASE WHEN success = 1 THEN 1.0 ELSE 0.0 END) * 100, 2) as successRate,
            ROUND(AVG(responseTime), 0) as averageResponseTime,
            MAX(timestamp) as lastChecked
          FROM requests 
          WHERE datetime(timestamp) >= datetime('now', '-24 hours')
          GROUP BY url, name, group_name, countryCode
          ORDER BY name;
        " > public/api/stats.json 2>/dev/null || echo "[]" > public/api/stats.json
        
        # Generate group-hierarchy.json for dashboard drilldown
        node -e "
          const sqlite3 = require('sqlite3');
          const fs = require('fs');
          
          try {
            const db = new sqlite3.Database('monitor.db');
            db.all('SELECT DISTINCT group_name, countryCode, url, name FROM requests WHERE group_name IS NOT NULL AND group_name != \"\"', (err, rows) => {
              if (err || !rows) {
                fs.writeFileSync('public/api/group-hierarchy.json', '[]');
                db.close();
                return;
              }
              
              const hierarchyMap = new Map();
              rows.forEach(row => {
                const key = \`\${row.group_name}|\${row.countryCode || 'no-country'}\`;
                if (!hierarchyMap.has(key)) {
                  hierarchyMap.set(key, {
                    group_name: row.group_name,
                    countryCode: row.countryCode || undefined,
                    urls: []
                  });
                }
                const entry = hierarchyMap.get(key);
                if (!entry.urls.find(u => u.url === row.url)) {
                  entry.urls.push({ url: row.url, name: row.name });
                }
              });
              
              const hierarchy = Array.from(hierarchyMap.values());
              fs.writeFileSync('public/api/group-hierarchy.json', JSON.stringify(hierarchy, null, 2));
              console.log(\`Generated hierarchy with \${hierarchy.length} groups\`);
              db.close();
            });
          } catch (error) {
            console.error('Error generating hierarchy:', error);
            require('fs').writeFileSync('public/api/group-hierarchy.json', '[]');
          }
        " || echo "[]" > public/api/group-hierarchy.json
        
        echo "✅ Static API files generated"
        echo "File sizes:"
        ls -lh public/api/

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./public
        enable_jekyll: false
        user_name: 'github-actions[bot]'
        user_email: 'github-actions[bot]@users.noreply.github.com'

    - name: Monitoring summary
      run: |
        echo "🎉 URL monitoring cycle completed!"
        echo "📊 Database: $(ls -lh monitor.db | awk '{print $5}')"
        echo "📁 API files: $(ls public/api/ | wc -l) generated"
        echo "🔄 Next run: $(date -d '+15 minutes' -u '+%Y-%m-%d %H:%M UTC')"